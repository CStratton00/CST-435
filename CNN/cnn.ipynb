{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "Joe Samyn and Collin Stratton\n",
    "\n",
    "CST-435\n",
    "\n",
    "Professor James Gordon\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the realm of deep learning, convolutional neural networks are a class of deep neural networks that are most commonly applied to analyze images. These neural networks take an input image, assign importance (learnable weights and biases) to various aspects/objects in the image, and use these weights and biases to differentiate one image from another. The preprocessing steps in a CNN are much smaller than many other classification algorithms. The architecture of a CNN is very similar to a multilayered perceptron. There are layers comprised of multiple perceptrons that fire when they produce an output above a certain threshold. This notebook will utilize a convolutional neural network to classify images from the CIFAR dataset. The goal is to create a network that can classify images with at least 70% accuracy. \n",
    "\n",
    "### CNN New Concepts\n",
    "Convolutional neural networks are a type of neural network similar to a multilayer perceptron. They maintain a lot of the same characteristics and still use multiple layers to construct a network that can perform a task accurately and efficiently. There are four key concepts that differentiate a convolutional neural network from an artificaul neural network: image data, convolutional layer, pooling layer, and the CNN base architecture. \n",
    "\n",
    "#### Image Data\n",
    "Convolutional neural networks are primarily used to classify image data. So, the primary input being deconstructed and manipulated are matrices if pixel data from the image. This input data is typically made up of three dimensions, the height of the image, the width of the image, and the color channels that make up the image. The color channel represents which colors are used to make up the image. For example, an image with an RGB color channel has three values that make up every pixel, a red value, green value, and blue value. Typically these values range from 0-255. So, a particular pixel will have the following data that represents its color channel (20, 155, 110). \n",
    "\n",
    "#### Convolutional Layers\n",
    "Every CNN is made up of at least one convolutional layer. These convolutional layers are tasked with the job of finding patterns within images that can be used to classify the entire image or parts of the image. They are similar to a dense layer in an ANN. The difference being that dense layers look for global patterns while convolutional layers look for local patterns. \n",
    "\n",
    "#### Convolutional Neural Network Base Architecture\n",
    "CNN's typically are comprised of many convolutional layers. Even very basic examples that are performing simple classification are made up of three or more convolutional layers. These layers work together to help increase the accuracy and performance of the network. For example, one layer might be responsible for detecting lines with certain lengths or angles. The next layer would be responsible for taking these layers and attempting to form shapes or polygons that can assist with performing an accurate classification. This pattern continues throughout the convolutional layers. The layers in a CNN are defines by two key parameters: filters and sample size. \n",
    "\n",
    "##### Filters \n",
    "A filter is an m x n pattern of pixels that matches our search criteria in an image. The output of filters is essentially a matrix representing the layers and a value indicating whether that filter was found in the particular layer or not. \n",
    "\n",
    "##### Sample Size\n",
    "Sample size is essentially the size block that each layer will be analyzing. A block is the m x n pixel grid that is being passed into the layer. For example a 3x3 block is a 3 pixel by 3 pixel piece of an image that is being analyzed in a layer. \n",
    "\n",
    "#### Pooling\n",
    "A pooling layer is a layer that is responsible for down sampling a feature map and reducing their dimensions. \n",
    "\n",
    "### Data Set\n",
    "The data set that was chosen for this example is the CIFAR image data set. The CIFAR dataset contains 60,000 32x32 color images of 10 different categories of every day objects. The 10 different classes of images are:\n",
    "- Airplane\n",
    "- Automobile\n",
    "- Bird\n",
    "- Cat\n",
    "- Deer\n",
    "- Dog\n",
    "- Frog\n",
    "- Horse\n",
    "- Ship\n",
    "- Truck\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Load image data from remote repository\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "IMG_INDEX = 7 \n",
    "\n",
    "# Display image at index 7\n",
    "plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)\n",
    "\n",
    "# Add X label \n",
    "plt.xlabel(class_names[train_labels[IMG_INDEX][0]])\n",
    "\n",
    "# Display the image using matplot lib\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "#### Layer 1\n",
    "The images are 32 x 32 x 3. This means we have a width of 32 pixels, height od 32 pixels, and a color channel of 3 values (r, g ,b).  The first layer will take this input data shape and process 32 filters of size 3x3. The activation function being used is a rectified linear unit. This activation function outputs the calculated output if it is positive. If it is negative it outputs a 0. \n",
    "\n",
    "#### Layer 2\n",
    "This layer will perform a pooling operation of 2x2 samples with a stride of 2. \n",
    "\n",
    "#### Layer 3\n",
    "Another convolutional layer that increases the filters being used from 32 to 64 filters of size 3 x 3. The ReLU activation function is being used to determine the output. \n",
    "\n",
    "#### Layer 4\n",
    "Another pooling operation of 2x2 samples with a stride of 2. \n",
    "\n",
    "#### Layer 5\n",
    "Another convolutional layer that increases the filters being used from 32 to 64 filters of size 3 x 3. The ReLU activation function is being used to determine the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 56,320\n",
      "Trainable params: 56,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Add convolutional base to network\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add a convulotional 2D layer using the ReLU activation function\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "\n",
    "# Perform max pooling operation using 2x2 samples and a stride of 2\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add 3 more layers increading frequency of filters from 32 to 64\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Print the summary of the model that has been created so far\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Dense Layers\n",
    "Now that we have the convolutional layers in place, we need to add some layers that will actually perform the classification. We use these dense layers to flatten our data to a 64-node dense layer and feed it into a 10 neuron output layer. We use 10 neurons for output because we have 10 different classes we are trying to use for classification. There are other methods for determining the number of output neurons, for example using 4 binary perceptrons and output binary numbers between 1 and 10, but for the sake of simplicity we will use one output neuron for each category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 122,570\n",
      "Trainable params: 122,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Adding Dense Layers\n",
    "# Flatten the layers from 32x32 to 64\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Add a dense layer with 64 nodes using the ReLU activation function\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Add second dense output layer with 10 neurons\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "# show updated summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "Now that we have a basic model compiled, we need to train the model on the training data. The optimization algorithm being used is adaptive moment estimation (adam). The metric that we are most interested in is the accuracy. Therefore, we tell tensorflow to output this accuracy value after each epoch. The fitting of the model will use 10 epochs. This model was run mutliple times with a different amount of epochs used each time. After 10 epochs, diminishing returns begin to appear. Finally, once the training is completed, the model is validated using the validation data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 26s 16ms/step - loss: 0.8838 - accuracy: 0.6901 - val_loss: 0.9130 - val_accuracy: 0.6855\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.8285 - accuracy: 0.7103 - val_loss: 0.9391 - val_accuracy: 0.6770\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.7824 - accuracy: 0.7272 - val_loss: 0.8840 - val_accuracy: 0.6968\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.7384 - accuracy: 0.7407 - val_loss: 0.9477 - val_accuracy: 0.6809\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.6993 - accuracy: 0.7559 - val_loss: 0.8781 - val_accuracy: 0.7060\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.6583 - accuracy: 0.7693 - val_loss: 0.8959 - val_accuracy: 0.7066\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.6207 - accuracy: 0.7811 - val_loss: 0.8957 - val_accuracy: 0.7113\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.5915 - accuracy: 0.7933 - val_loss: 0.8940 - val_accuracy: 0.7081\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.5622 - accuracy: 0.8034 - val_loss: 0.9002 - val_accuracy: 0.7093\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.5355 - accuracy: 0.8126 - val_loss: 0.9447 - val_accuracy: 0.7099\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "# build the model using the ADAM optimization technique and display the accuracy metrix. \n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "# Fit the model using the training images that were obtained in the data download step\n",
    "history = model.fit(train_images, train_labels, epochs=10,\n",
    "validation_data=(test_images, test_labels)) # validate the model using the test images and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "The convolutional neural network that was built in this example had an accuracy of 70%. There are things that could be done to help increase the accuracy of the network. One area that could be investigated is the activation functions used in the convolutional layers. Every convolutional layer uses the ReLU activation function, however different activation functions could be used to determine the best one for this group of images. There could also be more convolutional layers added to help target more features in the image. This route was not explored because we were trying to keep computation times at a minimum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.9447 - accuracy: 0.7099\n",
      "0.7099000215530396\n"
     ]
    }
   ],
   "source": [
    "# Calculate the estimated loss, accuracy using the evaluate method\n",
    "est_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "\n",
    "# show the test results\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Brownlee, J. (2020, August 20). A Gentle Introduction to the Rectified Linear Unit (ReLU). Machine Learning Mastery. https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/CS231n \n",
    "<br>\n",
    "Convolutional Neural Networks for Visual Recognition. (n.d.). Cs231n.Github.Io. Retrieved October 14, 2021, from https://cs231n.github.io/convolutional-networks/Pai, A. (2020, October 19). \n",
    "<br>\n",
    "ANN vs CNN vs RNN | Types of Neural Networks. Analytics Vidhya. https://www.analyticsvidhya.com/blog/2020/02/cnn-vs-rnn-vs-mlp-analyzing-3-types-of-neural-networks-in-deep-learning/Ruder, S. (2020, March 20). \n",
    "<br>\n",
    "An overview of gradient descent optimization algorithms. Sebastian Ruder. https://ruder.io/optimizing-gradient-descent/index.html#adamW. (2021, March 14). \n",
    "<br>\n",
    "Convolutional Neural Network With Tensorflow and Keras. Medium. https://medium.com/geekculture/introduction-to-convolutional-neural-network-with-tensorflow-and-keras-cb52cdc66eaf"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f1ecb2e8a2239e476eac45df7e6644f520933021358bd9eab50634128a1cd48"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
